{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pre_processing.textProcessing import TextPreProcessor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import precision_score, recall_score, auc, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def evaluate_classifier(y_true, y_pred, print_result=False):\n",
    "    \"\"\"\n",
    "    Given a predicted and true value, get the performance measurement of the classifier\n",
    "    \"\"\"\n",
    "    accr=accuracy_score(y_true, y_pred)\n",
    "    precision=precision_score(y_true,y_pred)\n",
    "    recall=recall_score(y_true,y_pred)\n",
    "    pct_maj = max(np.mean(y_true), 1-np.mean(y_true))\n",
    "    \n",
    "    if print_result:\n",
    "        print(f\"% majority class: {pct_maj}, Accuracy: {accr}, Precision: {precision}, Recall: {recall}\")\n",
    "    return (pct_maj, accr, precision, recall)\n",
    "\n",
    "def undersample_data(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Undersample data\n",
    "    \"\"\"\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def get_model_output(model, X_train, Y_train, X_test, Y_test, model_name='', y_labels=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], undersample=False):\n",
    "    \"\"\"\n",
    "    Automated the training and performance of traditional ML models\n",
    "    \"\"\"\n",
    "    output = pd.DataFrame(columns=['model_name', 'label','undersampled','pct_maj_class','accr','precision','recall'])\n",
    "    for label in y_labels:\n",
    "        # Get the label to use\n",
    "        y_train = Y_train[label]\n",
    "        y_test = Y_test[label]\n",
    "        \n",
    "        if undersample:\n",
    "            X, y = undersample_data(X_train, y_train)\n",
    "        else:\n",
    "            X, y = X_train, y_train\n",
    "  \n",
    "        # Fit the model\n",
    "        fitted = model.fit(X, y)\n",
    "        pred = fitted.predict(X_test)\n",
    "        \n",
    "        # Get the results\n",
    "        result = [model_name, label, undersample] + list(evaluate_classifier(y_true=y_test, y_pred=pred))\n",
    "        output.loc[len(output)] = result\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: (119678,)\n",
      "Shape of the testing set: (39893,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Sample the data\n",
    "# train = train.sample(10000, random_state=1)\n",
    "labels = train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "\n",
    "## Traning and testing split\n",
    "random.seed(923)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train.comment_text, labels, test_size = 0.25,random_state = 23)\n",
    "\n",
    "X_train.reset_index(drop = True,inplace = True)\n",
    "X_test.reset_index(drop = True,inplace = True)\n",
    "Y_train.reset_index(drop = True,inplace = True)\n",
    "Y_test.reset_index(drop = True,inplace = True)\n",
    "\n",
    "print(f\"Shape of the training set: {X_train.shape}\")\n",
    "print(f\"Shape of the testing set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.describe()\n",
    "# classified = train.iloc[:, 2:].sum(axis=1)\n",
    "# # Check for records that have no classifications and data imbalance\n",
    "# train['empty_cat'] = (classified == 0)\n",
    "# train['empty_cat'] = train['empty_cat'].astype(int)\n",
    "\n",
    "\n",
    "# def wordcloud(column, colormap, value = True):\n",
    "#     if value: \n",
    "#         subset = train[train[column] == value]\n",
    "#     else: \n",
    "#         subset = train[train[column] == 1]\n",
    "#     text = subset.comment_text.values\n",
    "    \n",
    "# #     image_path = './input/images/'+image\n",
    "# #     my_mask = np.array(Image.open(image_path))\n",
    "# #     my_mask = my_mask[:,:,1]\n",
    "    \n",
    "#     word = WordCloud(width = 1400, height =800,\n",
    "#                     background_color = 'white',\n",
    "#                     #mask = my_mask,\n",
    "#                     max_words = 3000,\n",
    "#                     random_state = 50,\n",
    "#                     #scale  = 2 \n",
    "#                     ).generate(' '.join(text))\n",
    "#     plt.axis('off')\n",
    "#     plt.title(f'High frequency words in {column.title()} Comments', fontsize = 20)\n",
    "#     plt.imshow(word.recolor(colormap = colormap, random_state = 17))\n",
    "    \n",
    "# plt.figure(figsize = (12,12))\n",
    "# wordcloud('empty_cat', 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (12,12))\n",
    "# wordcloud('threat', 'Wistia', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labels by Label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "empty_cat            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of Labels by Label')\n",
    "label_count = train.iloc[:, 2:].sum()\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for records that have multiple classifications\n",
    "classified = train.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "mult_class = classified.value_counts()\n",
    "\n",
    "mult_class.plot(x=mult_class, \n",
    "             y=mult_class.values, \n",
    "             kind='bar', \n",
    "             xlabel='Number of Labels', \n",
    "             ylabel='Records')\n",
    "plt.title('Number of Labels per Record')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of Labels by Label')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for records that have no classifications and data imbalance\n",
    "train['empty_cat'] = (classified == 0)\n",
    "train['empty_cat'] = train['empty_cat'].astype(int)\n",
    " \n",
    "cat_tot = train.iloc[:, 2:].sum()\n",
    "\n",
    "cat_tot.plot(x=cat_tot, \n",
    "             y=cat_tot.values, \n",
    "             kind='bar', \n",
    "             xlabel='Label', \n",
    "             ylabel='Records')\n",
    "plt.title('Number of Labels by Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments: 159571\n",
      "Total nontoxic comments: 143346\n",
      "Total toxic comments: 16225\n",
      "Total labels: 35098\n"
     ]
    }
   ],
   "source": [
    "print('Total comments:', len(train))\n",
    "print('Total nontoxic comments:', train['empty_cat'].sum())\n",
    "print('Total toxic comments:', len(train) - train['empty_cat'].sum())\n",
    "print('Total labels:' , train.loc[:, 'toxic':'identity_hate'].sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "In this section, we will pre-process the data into two kinds of formats:\n",
    "\n",
    "1. Document-Term Matrix\n",
    "2. Padded numeric sequences\n",
    "\n",
    "We will use the DTM for non RNN models, and the padded numeric sequences for recurrent neural net work based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the documents into DTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoma/envs/ds207/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  \"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Define a function that take in a text and process the doc\n",
    "    \"\"\"\n",
    "    return TextPreProcessor(text=text, lemma_flag=True, stem_flag=False).process()\n",
    "\n",
    "# Fit a tf-idf vectorizer and filter-out the terms with less than 15 occurances or appears in more than 90% of the documents \n",
    "vec_tfidf = TfidfVectorizer(ngram_range=(1,1),tokenizer=tokenize,min_df=15, max_df=0.9)\n",
    "vec_tfidf_fitted = vec_tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_DTM = vec_tfidf_fitted.transform(X_train)\n",
    "X_test_DTM = vec_tfidf_fitted.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11275</th>\n",
       "      <th>11276</th>\n",
       "      <th>11277</th>\n",
       "      <th>11278</th>\n",
       "      <th>11279</th>\n",
       "      <th>11280</th>\n",
       "      <th>11281</th>\n",
       "      <th>11282</th>\n",
       "      <th>11283</th>\n",
       "      <th>11284</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.304312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1      2      3      4      5         6      7      8      \\\n",
       "0  0.000000  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "1  0.304312  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "2  0.000000  0.057764    0.0    0.0    0.0    0.0  0.116291    0.0    0.0   \n",
       "3  0.000000  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "4  0.000000  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0    0.0   \n",
       "\n",
       "   9      ...  11275  11276  11277  11278  11279  11280  11281  11282  11283  \\\n",
       "0    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   11284  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 11285 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_DTM.toarray()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the documents into padded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "That's correct. A smaller diameter is held less securely by the sphincter, and is less efficient at allowing gas through.\n",
      "Vectorized:\n",
      "[203, 365, 5, 2894, 5001, 8, 1603, 460, 5001, 31, 1, 5001, 4, 8, 460, 5001, 34, 2946, 2853, 334]\n",
      "Padded:\n",
      "[ 203  365    5 2894 5001    8 1603  460 5001   31    1 5001    4    8\n",
      "  460 5001   34 2946 2853  334    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "# Create the tokenizer\n",
    "t = Tokenizer()\n",
    "# Fit the tokenizer on the documents\n",
    "t.fit_on_texts(X_train)\n",
    "\n",
    "\"\"\"\n",
    "The word index for keras Tokenizer is ordered based on frequency. Therefore we can do the following according to\n",
    "https://github.com/keras-team/keras/issues/8092\n",
    "\"\"\"\n",
    "t.oov_token = '_unknown_'\n",
    "t.word_index = {e:i for e,i in t.word_index.items() if i <= VOCAB_SIZE} # <= because tokenizer is 1 indexed\n",
    "t.word_index[t.oov_token] = VOCAB_SIZE + 1\n",
    "\n",
    "\"\"\"\n",
    "Apply the tokenizer\n",
    "\"\"\"\n",
    "encoded_docs = t.texts_to_sequences(X_train)\n",
    "\n",
    "\"\"\"\n",
    "Padd the sequences\n",
    "\"\"\"\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post')\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(X_train[0])\n",
    "print(\"Vectorized:\")\n",
    "print(encoded_docs[0])\n",
    "print(\"Padded:\")\n",
    "print(padded_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoma/envs/ds207/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.946407</td>\n",
       "      <td>0.933132</td>\n",
       "      <td>0.480704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.031785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.970797</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.483917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.966611</td>\n",
       "      <td>0.848283</td>\n",
       "      <td>0.390617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.990976</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.008287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>0.895623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.920588</td>\n",
       "      <td>0.112391</td>\n",
       "      <td>0.977995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.890658</td>\n",
       "      <td>0.314020</td>\n",
       "      <td>0.923668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.907202</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.888978</td>\n",
       "      <td>0.296973</td>\n",
       "      <td>0.920449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.898579</td>\n",
       "      <td>0.077329</td>\n",
       "      <td>0.930939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name          label undersampled  pct_maj_class      accr  \\\n",
       "0   Naive Bayes          toxic        False       0.903216  0.946407   \n",
       "1   Naive Bayes   severe_toxic        False       0.989748  0.989823   \n",
       "2   Naive Bayes        obscene        False       0.947785  0.970797   \n",
       "3   Naive Bayes         threat        False       0.997218  0.997218   \n",
       "4   Naive Bayes         insult        False       0.950844  0.966611   \n",
       "5   Naive Bayes  identity_hate        False       0.990926  0.990976   \n",
       "6   Naive Bayes          toxic         True       0.903216  0.881333   \n",
       "7   Naive Bayes   severe_toxic         True       0.989748  0.920588   \n",
       "8   Naive Bayes        obscene         True       0.947785  0.890658   \n",
       "9   Naive Bayes         threat         True       0.997218  0.907202   \n",
       "10  Naive Bayes         insult         True       0.950844  0.888978   \n",
       "11  Naive Bayes  identity_hate         True       0.990926  0.898579   \n",
       "\n",
       "    precision    recall  \n",
       "0    0.933132  0.480704  \n",
       "1    0.565217  0.031785  \n",
       "2    0.918033  0.483917  \n",
       "3    0.000000  0.000000  \n",
       "4    0.848283  0.390617  \n",
       "5    0.750000  0.008287  \n",
       "6    0.443959  0.895623  \n",
       "7    0.112391  0.977995  \n",
       "8    0.314020  0.923668  \n",
       "9    0.027624  0.945946  \n",
       "10   0.296973  0.920449  \n",
       "11   0.077329  0.930939  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "non_undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Naive Bayes',\n",
    "    undersample=False\n",
    ")\n",
    "\n",
    "undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Naive Bayes',\n",
    "    undersample=True\n",
    ")\n",
    "\n",
    "multi_nb_results = non_undersampled.append(undersampled, ignore_index=True)\n",
    "multi_nb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logicstic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoma/envs/ds207/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/xiaoma/envs/ds207/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "non_undersampled = get_model_output(\n",
    "    LogisticRegression(), \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Logistic Regression',\n",
    "    undersample=False\n",
    ")\n",
    "\n",
    "undersampled = get_model_output(\n",
    "    LogisticRegression(), \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Logistic Regression',\n",
    "    undersample=True\n",
    ")\n",
    "\n",
    "logicstic_regression_results = non_undersampled.append(undersampled, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.957612</td>\n",
       "      <td>0.918596</td>\n",
       "      <td>0.616680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.989873</td>\n",
       "      <td>0.513966</td>\n",
       "      <td>0.224939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.977715</td>\n",
       "      <td>0.903924</td>\n",
       "      <td>0.641383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997142</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.063063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.971173</td>\n",
       "      <td>0.826227</td>\n",
       "      <td>0.523712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.991653</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.168508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.921941</td>\n",
       "      <td>0.562406</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.957135</td>\n",
       "      <td>0.183763</td>\n",
       "      <td>0.924205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.956534</td>\n",
       "      <td>0.551399</td>\n",
       "      <td>0.898704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.946933</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>0.828829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.936881</td>\n",
       "      <td>0.432023</td>\n",
       "      <td>0.902601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.933121</td>\n",
       "      <td>0.107021</td>\n",
       "      <td>0.867403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name          label undersampled  pct_maj_class      accr  \\\n",
       "0   Logistic Regression          toxic        False       0.903216  0.957612   \n",
       "1   Logistic Regression   severe_toxic        False       0.989748  0.989873   \n",
       "2   Logistic Regression        obscene        False       0.947785  0.977715   \n",
       "3   Logistic Regression         threat        False       0.997218  0.997142   \n",
       "4   Logistic Regression         insult        False       0.950844  0.971173   \n",
       "5   Logistic Regression  identity_hate        False       0.990926  0.991653   \n",
       "6   Logistic Regression          toxic         True       0.903216  0.921941   \n",
       "7   Logistic Regression   severe_toxic         True       0.989748  0.957135   \n",
       "8   Logistic Regression        obscene         True       0.947785  0.956534   \n",
       "9   Logistic Regression         threat         True       0.997218  0.946933   \n",
       "10  Logistic Regression         insult         True       0.950844  0.936881   \n",
       "11  Logistic Regression  identity_hate         True       0.990926  0.933121   \n",
       "\n",
       "    precision    recall  \n",
       "0    0.918596  0.616680  \n",
       "1    0.513966  0.224939  \n",
       "2    0.903924  0.641383  \n",
       "3    0.411765  0.063063  \n",
       "4    0.826227  0.523712  \n",
       "5    0.655914  0.168508  \n",
       "6    0.562406  0.871795  \n",
       "7    0.183763  0.924205  \n",
       "8    0.551399  0.898704  \n",
       "9    0.042009  0.828829  \n",
       "10   0.432023  0.902601  \n",
       "11   0.107021  0.867403  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logicstic_regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.960344</td>\n",
       "      <td>0.874220</td>\n",
       "      <td>0.689459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.989547</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.224939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.978718</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>0.704273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997293</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.171171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.971624</td>\n",
       "      <td>0.782165</td>\n",
       "      <td>0.585926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.992029</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.259669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.913945</td>\n",
       "      <td>0.533385</td>\n",
       "      <td>0.885522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.945880</td>\n",
       "      <td>0.153053</td>\n",
       "      <td>0.943765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.949289</td>\n",
       "      <td>0.507970</td>\n",
       "      <td>0.917907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.942321</td>\n",
       "      <td>0.042224</td>\n",
       "      <td>0.909910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.927180</td>\n",
       "      <td>0.395251</td>\n",
       "      <td>0.908210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.924297</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>0.903315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name          label undersampled  pct_maj_class      accr  \\\n",
       "0   Linear SVC          toxic        False       0.903216  0.960344   \n",
       "1   Linear SVC   severe_toxic        False       0.989748  0.989547   \n",
       "2   Linear SVC        obscene        False       0.947785  0.978718   \n",
       "3   Linear SVC         threat        False       0.997218  0.997293   \n",
       "4   Linear SVC         insult        False       0.950844  0.971624   \n",
       "5   Linear SVC  identity_hate        False       0.990926  0.992029   \n",
       "6   Linear SVC          toxic         True       0.903216  0.913945   \n",
       "7   Linear SVC   severe_toxic         True       0.989748  0.945880   \n",
       "8   Linear SVC        obscene         True       0.947785  0.949289   \n",
       "9   Linear SVC         threat         True       0.997218  0.942321   \n",
       "10  Linear SVC         insult         True       0.950844  0.927180   \n",
       "11  Linear SVC  identity_hate         True       0.990926  0.924297   \n",
       "\n",
       "    precision    recall  \n",
       "0    0.874220  0.689459  \n",
       "1    0.479167  0.224939  \n",
       "2    0.862941  0.704273  \n",
       "3    0.542857  0.171171  \n",
       "4    0.782165  0.585926  \n",
       "5    0.652778  0.259669  \n",
       "6    0.533385  0.885522  \n",
       "7    0.153053  0.943765  \n",
       "8    0.507970  0.917907  \n",
       "9    0.042224  0.909910  \n",
       "10   0.395251  0.908210  \n",
       "11   0.098732  0.903315  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "non_undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Linear SVC',\n",
    "    undersample=False\n",
    ")\n",
    "\n",
    "undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Linear SVC',\n",
    "    undersample=True\n",
    ")\n",
    "\n",
    "svc_results = non_undersampled.append(undersampled, ignore_index=True)\n",
    "svc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.954754</td>\n",
       "      <td>0.910543</td>\n",
       "      <td>0.590521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.989948</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.066015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.979595</td>\n",
       "      <td>0.891909</td>\n",
       "      <td>0.693231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997293</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.045045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.969518</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.515043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.991126</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.074586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.888978</td>\n",
       "      <td>0.459602</td>\n",
       "      <td>0.836830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.904645</td>\n",
       "      <td>0.092241</td>\n",
       "      <td>0.938875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.923972</td>\n",
       "      <td>0.397497</td>\n",
       "      <td>0.884301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.883914</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.899531</td>\n",
       "      <td>0.312374</td>\n",
       "      <td>0.868944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.855513</td>\n",
       "      <td>0.052815</td>\n",
       "      <td>0.881215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_name          label undersampled  pct_maj_class  \\\n",
       "0   Random Forest (200 trees)          toxic        False       0.903216   \n",
       "1   Random Forest (200 trees)   severe_toxic        False       0.989748   \n",
       "2   Random Forest (200 trees)        obscene        False       0.947785   \n",
       "3   Random Forest (200 trees)         threat        False       0.997218   \n",
       "4   Random Forest (200 trees)         insult        False       0.950844   \n",
       "5   Random Forest (200 trees)  identity_hate        False       0.990926   \n",
       "6   Random Forest (200 trees)          toxic         True       0.903216   \n",
       "7   Random Forest (200 trees)   severe_toxic         True       0.989748   \n",
       "8   Random Forest (200 trees)        obscene         True       0.947785   \n",
       "9   Random Forest (200 trees)         threat         True       0.997218   \n",
       "10  Random Forest (200 trees)         insult         True       0.950844   \n",
       "11  Random Forest (200 trees)  identity_hate         True       0.990926   \n",
       "\n",
       "        accr  precision    recall  \n",
       "0   0.954754   0.910543  0.590521  \n",
       "1   0.989948   0.586957  0.066015  \n",
       "2   0.979595   0.891909  0.693231  \n",
       "3   0.997293   0.714286  0.045045  \n",
       "4   0.969518   0.792157  0.515043  \n",
       "5   0.991126   0.586957  0.074586  \n",
       "6   0.888978   0.459602  0.836830  \n",
       "7   0.904645   0.092241  0.938875  \n",
       "8   0.923972   0.397497  0.884301  \n",
       "9   0.883914   0.021592  0.918919  \n",
       "10  0.899531   0.312374  0.868944  \n",
       "11  0.855513   0.052815  0.881215  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "non_undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Random Forest (200 trees)',\n",
    "    undersample=False\n",
    ")\n",
    "\n",
    "undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='Random Forest (200 trees)',\n",
    "    undersample=True\n",
    ")\n",
    "\n",
    "rf_results = non_undersampled.append(undersampled, ignore_index=True)\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.954754</td>\n",
       "      <td>0.910543</td>\n",
       "      <td>0.590521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.989948</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.066015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.979595</td>\n",
       "      <td>0.891909</td>\n",
       "      <td>0.693231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997293</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.045045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.969518</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.515043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.991126</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.074586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.888978</td>\n",
       "      <td>0.459602</td>\n",
       "      <td>0.836830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.904645</td>\n",
       "      <td>0.092241</td>\n",
       "      <td>0.938875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.923972</td>\n",
       "      <td>0.397497</td>\n",
       "      <td>0.884301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.883914</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.899531</td>\n",
       "      <td>0.312374</td>\n",
       "      <td>0.868944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.855513</td>\n",
       "      <td>0.052815</td>\n",
       "      <td>0.881215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_name          label undersampled  pct_maj_class  \\\n",
       "0   Random Forest (200 trees)          toxic        False       0.903216   \n",
       "1   Random Forest (200 trees)   severe_toxic        False       0.989748   \n",
       "2   Random Forest (200 trees)        obscene        False       0.947785   \n",
       "3   Random Forest (200 trees)         threat        False       0.997218   \n",
       "4   Random Forest (200 trees)         insult        False       0.950844   \n",
       "5   Random Forest (200 trees)  identity_hate        False       0.990926   \n",
       "6   Random Forest (200 trees)          toxic         True       0.903216   \n",
       "7   Random Forest (200 trees)   severe_toxic         True       0.989748   \n",
       "8   Random Forest (200 trees)        obscene         True       0.947785   \n",
       "9   Random Forest (200 trees)         threat         True       0.997218   \n",
       "10  Random Forest (200 trees)         insult         True       0.950844   \n",
       "11  Random Forest (200 trees)  identity_hate         True       0.990926   \n",
       "\n",
       "        accr  precision    recall  \n",
       "0   0.954754   0.910543  0.590521  \n",
       "1   0.989948   0.586957  0.066015  \n",
       "2   0.979595   0.891909  0.693231  \n",
       "3   0.997293   0.714286  0.045045  \n",
       "4   0.969518   0.792157  0.515043  \n",
       "5   0.991126   0.586957  0.074586  \n",
       "6   0.888978   0.459602  0.836830  \n",
       "7   0.904645   0.092241  0.938875  \n",
       "8   0.923972   0.397497  0.884301  \n",
       "9   0.883914   0.021592  0.918919  \n",
       "10  0.899531   0.312374  0.868944  \n",
       "11  0.855513   0.052815  0.881215  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.958238</td>\n",
       "      <td>0.902457</td>\n",
       "      <td>0.637400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.989672</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0.266504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.980448</td>\n",
       "      <td>0.863358</td>\n",
       "      <td>0.743159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997318</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.971850</td>\n",
       "      <td>0.777116</td>\n",
       "      <td>0.599184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.992079</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.309392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.921665</td>\n",
       "      <td>0.562373</td>\n",
       "      <td>0.859363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.941042</td>\n",
       "      <td>0.138444</td>\n",
       "      <td>0.909535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.958815</td>\n",
       "      <td>0.565632</td>\n",
       "      <td>0.910226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.906174</td>\n",
       "      <td>0.024358</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.935578</td>\n",
       "      <td>0.426680</td>\n",
       "      <td>0.903621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.920212</td>\n",
       "      <td>0.087694</td>\n",
       "      <td>0.828729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name          label undersampled  pct_maj_class      accr  \\\n",
       "0   XGBoost (200 trees)          toxic        False       0.903216  0.958238   \n",
       "1   XGBoost (200 trees)   severe_toxic        False       0.989748  0.989672   \n",
       "2   XGBoost (200 trees)        obscene        False       0.947785  0.980448   \n",
       "3   XGBoost (200 trees)         threat        False       0.997218  0.997318   \n",
       "4   XGBoost (200 trees)         insult        False       0.950844  0.971850   \n",
       "5   XGBoost (200 trees)  identity_hate        False       0.990926  0.992079   \n",
       "6   XGBoost (200 trees)          toxic         True       0.903216  0.921665   \n",
       "7   XGBoost (200 trees)   severe_toxic         True       0.989748  0.941042   \n",
       "8   XGBoost (200 trees)        obscene         True       0.947785  0.958815   \n",
       "9   XGBoost (200 trees)         threat         True       0.997218  0.906174   \n",
       "10  XGBoost (200 trees)         insult         True       0.950844  0.935578   \n",
       "11  XGBoost (200 trees)  identity_hate         True       0.990926  0.920212   \n",
       "\n",
       "    precision    recall  \n",
       "0    0.902457  0.637400  \n",
       "1    0.493213  0.266504  \n",
       "2    0.863358  0.743159  \n",
       "3    0.545455  0.216216  \n",
       "4    0.777116  0.599184  \n",
       "5    0.629213  0.309392  \n",
       "6    0.562373  0.859363  \n",
       "7    0.138444  0.909535  \n",
       "8    0.565632  0.910226  \n",
       "9    0.024358  0.837838  \n",
       "10   0.426680  0.903621  \n",
       "11   0.087694  0.828729  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(n_estimators=200)\n",
    "non_undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='XGBoost (200 trees)',\n",
    "    undersample=False\n",
    ")\n",
    "\n",
    "undersampled = get_model_output(\n",
    "    model, \n",
    "    X_train_DTM, \n",
    "    Y_train, \n",
    "    X_test_DTM, \n",
    "    Y_test, \n",
    "    model_name='XGBoost (200 trees)',\n",
    "    undersample=True\n",
    ")\n",
    "\n",
    "xgb_results = non_undersampled.append(undersampled, ignore_index=True)\n",
    "xgb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 01:53:18.580360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2992/2992 [==============================] - 647s 215ms/step - loss: 0.0777 - accuracy: 0.9602 - val_loss: 0.0563 - val_accuracy: 0.9939\n",
      "Epoch 2/20\n",
      "2992/2992 [==============================] - 626s 209ms/step - loss: 0.0533 - accuracy: 0.9940 - val_loss: 0.0533 - val_accuracy: 0.9939\n",
      "Epoch 3/20\n",
      "2992/2992 [==============================] - 624s 209ms/step - loss: 0.0500 - accuracy: 0.9940 - val_loss: 0.0529 - val_accuracy: 0.9939\n",
      "Epoch 4/20\n",
      "2992/2992 [==============================] - 628s 210ms/step - loss: 0.0479 - accuracy: 0.9938 - val_loss: 0.0533 - val_accuracy: 0.9938\n",
      "Epoch 5/20\n",
      "2992/2992 [==============================] - 627s 209ms/step - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.0530 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b7a04ab70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model 1: Bidirectional LSTM - not undersampled\n",
    "\"\"\"\n",
    "def create_model(vocab_size, num_labels, sequence_length):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(sequence_length,)),\n",
    "        layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=sequence_length, mask_zero=True),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Bidirectional(layers.LSTM(64,return_sequences = False,dropout = 0.2,recurrent_dropout = 0.2)),\n",
    "        layers.Dense(25,activation = 'relu'),\n",
    "        layers.Dense(num_labels,activation = 'sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_model(len(t.word_index)+1, num_labels=6, sequence_length=MAX_SEQUENCE_LENGTH)\n",
    "model.compile(\n",
    "    loss=losses.binary_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Define an early-stopping callback\n",
    "cb = [EarlyStopping(monitor='val_loss',patience = 2)]\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "model.fit(padded_docs, Y_train,validation_split=0.2,\\\n",
    "          batch_size=batch_size, epochs=num_epochs,verbose=1,callbacks =cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 33s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoma/envs/ds207/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xiaoma/envs/ds207/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "encoded_doc_test = t.texts_to_sequences(X_test)\n",
    "padded_doc_test = pad_sequences(encoded_doc_test, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post')\n",
    "pred = model.predict(padded_doc_test)\n",
    "\n",
    "\"\"\"\n",
    "Construct the final model\n",
    "\"\"\"\n",
    "model_name = 'Bi-LSTM + Embedding'\n",
    "undersampled = False\n",
    "bilstm_results = pd.DataFrame(columns=['model_name', 'label','undersampled','pct_maj_class','accr','precision','recall'])\n",
    "for i in range(6):\n",
    "    y_pred_bin = [x>0.5 for x in pred[:,i]]\n",
    "    label = Y_train.columns[i]\n",
    "    y_test = Y_test\n",
    "    result = [model_name, label, undersampled] + list(evaluate_classifier(y_true=y_test.iloc[:,i], y_pred=y_pred_bin))\n",
    "    bilstm_results.loc[len(bilstm_results)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.961221</td>\n",
       "      <td>0.830950</td>\n",
       "      <td>0.752396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.342298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.849604</td>\n",
       "      <td>0.772924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.722783</td>\n",
       "      <td>0.694034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name          label undersampled  pct_maj_class      accr  \\\n",
       "0  Bi-LSTM + Embedding          toxic        False       0.903216  0.961221   \n",
       "1  Bi-LSTM + Embedding   severe_toxic        False       0.989748  0.990099   \n",
       "2  Bi-LSTM + Embedding        obscene        False       0.947785  0.980999   \n",
       "3  Bi-LSTM + Embedding         threat        False       0.997218  0.997218   \n",
       "4  Bi-LSTM + Embedding         insult        False       0.950844  0.971875   \n",
       "5  Bi-LSTM + Embedding  identity_hate        False       0.990926  0.990926   \n",
       "\n",
       "   precision    recall  \n",
       "0   0.830950  0.752396  \n",
       "1   0.526316  0.342298  \n",
       "2   0.849604  0.772924  \n",
       "3   0.000000  0.000000  \n",
       "4   0.722783  0.694034  \n",
       "5   0.000000  0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel 2: LSTM only\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model 2: LSTM only\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([multi_nb_results, svc_results, logicstic_regression_results,rf_results,xgb_results,bilstm_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.946407</td>\n",
       "      <td>0.933132</td>\n",
       "      <td>0.480704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.031785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.970797</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.483917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.966611</td>\n",
       "      <td>0.848283</td>\n",
       "      <td>0.390617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.342298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>obscene</td>\n",
       "      <td>False</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.980999</td>\n",
       "      <td>0.849604</td>\n",
       "      <td>0.772924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>threat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>insult</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.722783</td>\n",
       "      <td>0.694034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bi-LSTM + Embedding</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>False</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name          label undersampled  pct_maj_class      accr  \\\n",
       "0           Naive Bayes          toxic        False       0.903216  0.946407   \n",
       "1           Naive Bayes   severe_toxic        False       0.989748  0.989823   \n",
       "2           Naive Bayes        obscene        False       0.947785  0.970797   \n",
       "3           Naive Bayes         threat        False       0.997218  0.997218   \n",
       "4           Naive Bayes         insult        False       0.950844  0.966611   \n",
       "..                  ...            ...          ...            ...       ...   \n",
       "1   Bi-LSTM + Embedding   severe_toxic        False       0.989748  0.990099   \n",
       "2   Bi-LSTM + Embedding        obscene        False       0.947785  0.980999   \n",
       "3   Bi-LSTM + Embedding         threat        False       0.997218  0.997218   \n",
       "4   Bi-LSTM + Embedding         insult        False       0.950844  0.971875   \n",
       "5   Bi-LSTM + Embedding  identity_hate        False       0.990926  0.990926   \n",
       "\n",
       "    precision    recall  \n",
       "0    0.933132  0.480704  \n",
       "1    0.565217  0.031785  \n",
       "2    0.918033  0.483917  \n",
       "3    0.000000  0.000000  \n",
       "4    0.848283  0.390617  \n",
       "..        ...       ...  \n",
       "1    0.526316  0.342298  \n",
       "2    0.849604  0.772924  \n",
       "3    0.000000  0.000000  \n",
       "4    0.722783  0.694034  \n",
       "5    0.000000  0.000000  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_csv('../output/all_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>undersampled</th>\n",
       "      <th>pct_maj_class</th>\n",
       "      <th>accr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>0.895623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.920588</td>\n",
       "      <td>0.112391</td>\n",
       "      <td>0.977995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.890658</td>\n",
       "      <td>0.314020</td>\n",
       "      <td>0.923668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.907202</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.888978</td>\n",
       "      <td>0.296973</td>\n",
       "      <td>0.920449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.898579</td>\n",
       "      <td>0.077329</td>\n",
       "      <td>0.930939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.913945</td>\n",
       "      <td>0.533385</td>\n",
       "      <td>0.885522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.945880</td>\n",
       "      <td>0.153053</td>\n",
       "      <td>0.943765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.949289</td>\n",
       "      <td>0.507970</td>\n",
       "      <td>0.917907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.942321</td>\n",
       "      <td>0.042224</td>\n",
       "      <td>0.909910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.927180</td>\n",
       "      <td>0.395251</td>\n",
       "      <td>0.908210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.924297</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>0.903315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.921941</td>\n",
       "      <td>0.562406</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.957135</td>\n",
       "      <td>0.183763</td>\n",
       "      <td>0.924205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.956534</td>\n",
       "      <td>0.551399</td>\n",
       "      <td>0.898704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.946933</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>0.828829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.936881</td>\n",
       "      <td>0.432023</td>\n",
       "      <td>0.902601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.933121</td>\n",
       "      <td>0.107021</td>\n",
       "      <td>0.867403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.888978</td>\n",
       "      <td>0.459602</td>\n",
       "      <td>0.836830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.904645</td>\n",
       "      <td>0.092241</td>\n",
       "      <td>0.938875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.923972</td>\n",
       "      <td>0.397497</td>\n",
       "      <td>0.884301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.883914</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.899531</td>\n",
       "      <td>0.312374</td>\n",
       "      <td>0.868944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.855513</td>\n",
       "      <td>0.052815</td>\n",
       "      <td>0.881215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903216</td>\n",
       "      <td>0.921665</td>\n",
       "      <td>0.562373</td>\n",
       "      <td>0.859363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.941042</td>\n",
       "      <td>0.138444</td>\n",
       "      <td>0.909535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>obscene</td>\n",
       "      <td>True</td>\n",
       "      <td>0.947785</td>\n",
       "      <td>0.958815</td>\n",
       "      <td>0.565632</td>\n",
       "      <td>0.910226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>threat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.906174</td>\n",
       "      <td>0.024358</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>insult</td>\n",
       "      <td>True</td>\n",
       "      <td>0.950844</td>\n",
       "      <td>0.935578</td>\n",
       "      <td>0.426680</td>\n",
       "      <td>0.903621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost (200 trees)</td>\n",
       "      <td>identity_hate</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.920212</td>\n",
       "      <td>0.087694</td>\n",
       "      <td>0.828729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_name          label undersampled  pct_maj_class  \\\n",
       "6                 Naive Bayes          toxic         True       0.903216   \n",
       "7                 Naive Bayes   severe_toxic         True       0.989748   \n",
       "8                 Naive Bayes        obscene         True       0.947785   \n",
       "9                 Naive Bayes         threat         True       0.997218   \n",
       "10                Naive Bayes         insult         True       0.950844   \n",
       "11                Naive Bayes  identity_hate         True       0.990926   \n",
       "6                  Linear SVC          toxic         True       0.903216   \n",
       "7                  Linear SVC   severe_toxic         True       0.989748   \n",
       "8                  Linear SVC        obscene         True       0.947785   \n",
       "9                  Linear SVC         threat         True       0.997218   \n",
       "10                 Linear SVC         insult         True       0.950844   \n",
       "11                 Linear SVC  identity_hate         True       0.990926   \n",
       "6         Logistic Regression          toxic         True       0.903216   \n",
       "7         Logistic Regression   severe_toxic         True       0.989748   \n",
       "8         Logistic Regression        obscene         True       0.947785   \n",
       "9         Logistic Regression         threat         True       0.997218   \n",
       "10        Logistic Regression         insult         True       0.950844   \n",
       "11        Logistic Regression  identity_hate         True       0.990926   \n",
       "6   Random Forest (200 trees)          toxic         True       0.903216   \n",
       "7   Random Forest (200 trees)   severe_toxic         True       0.989748   \n",
       "8   Random Forest (200 trees)        obscene         True       0.947785   \n",
       "9   Random Forest (200 trees)         threat         True       0.997218   \n",
       "10  Random Forest (200 trees)         insult         True       0.950844   \n",
       "11  Random Forest (200 trees)  identity_hate         True       0.990926   \n",
       "6         XGBoost (200 trees)          toxic         True       0.903216   \n",
       "7         XGBoost (200 trees)   severe_toxic         True       0.989748   \n",
       "8         XGBoost (200 trees)        obscene         True       0.947785   \n",
       "9         XGBoost (200 trees)         threat         True       0.997218   \n",
       "10        XGBoost (200 trees)         insult         True       0.950844   \n",
       "11        XGBoost (200 trees)  identity_hate         True       0.990926   \n",
       "\n",
       "        accr  precision    recall  \n",
       "6   0.881333   0.443959  0.895623  \n",
       "7   0.920588   0.112391  0.977995  \n",
       "8   0.890658   0.314020  0.923668  \n",
       "9   0.907202   0.027624  0.945946  \n",
       "10  0.888978   0.296973  0.920449  \n",
       "11  0.898579   0.077329  0.930939  \n",
       "6   0.913945   0.533385  0.885522  \n",
       "7   0.945880   0.153053  0.943765  \n",
       "8   0.949289   0.507970  0.917907  \n",
       "9   0.942321   0.042224  0.909910  \n",
       "10  0.927180   0.395251  0.908210  \n",
       "11  0.924297   0.098732  0.903315  \n",
       "6   0.921941   0.562406  0.871795  \n",
       "7   0.957135   0.183763  0.924205  \n",
       "8   0.956534   0.551399  0.898704  \n",
       "9   0.946933   0.042009  0.828829  \n",
       "10  0.936881   0.432023  0.902601  \n",
       "11  0.933121   0.107021  0.867403  \n",
       "6   0.888978   0.459602  0.836830  \n",
       "7   0.904645   0.092241  0.938875  \n",
       "8   0.923972   0.397497  0.884301  \n",
       "9   0.883914   0.021592  0.918919  \n",
       "10  0.899531   0.312374  0.868944  \n",
       "11  0.855513   0.052815  0.881215  \n",
       "6   0.921665   0.562373  0.859363  \n",
       "7   0.941042   0.138444  0.909535  \n",
       "8   0.958815   0.565632  0.910226  \n",
       "9   0.906174   0.024358  0.837838  \n",
       "10  0.935578   0.426680  0.903621  \n",
       "11  0.920212   0.087694  0.828729  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[all_results.undersampled==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds207",
   "language": "python",
   "name": "ds207"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
