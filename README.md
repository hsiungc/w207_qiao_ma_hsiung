<h1>Toxic Comment Classification</h1>

<h2>W207 Final Project - Qian Qiao, Marshal Ma, Casey Hsiung</h2>

<h3>Overview</h3>

<p>
Social media and online platforms have provided a great place for individuals to express their thoughts and opinions freely. However, some comments contain negative and even explicit language, which may hurt the readers and even evolve into media violence and cyberbullying.
</p>

<p>
To protect users and create a good atmosphere for communication, more and more platforms and companies have started to identify those toxic comments and block users who are found guilty of using unpleasant language.
</p>

With this motivation, we decide to choose the Kaggle challenge, 'Toxic Comment Classification' as our team project. Our goal is to create a model to predict different types of toxicity for online comments, based on labels related to threats, obscenity, insults, and identity-based hate.
</p>